{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBGEws_BNH2P"
   },
   "source": [
    "# 1.1「学習済みVGGモデル」を使用する方法\n",
    "\n",
    "- 本ファイルでは、学習済みのVGGモデルを使用し、未知の画像（ゴールデンレトリバー）を分類します\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBfSv2DyNH2W"
   },
   "source": [
    "# 学習目標\n",
    "\n",
    "1.\tPyTorchでImangeNetデータセットでの学習済みモデルをロードできるようになる\n",
    "2.\tVGGモデルについて理解する\n",
    "3.\t入力画像のサイズや色を変換できるようになる\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6H1SGoeNH2X"
   },
   "source": [
    "# 事前準備\n",
    "\n",
    "\n",
    "1. 書籍の指示に従い、make_folders_and_data_downloads.ipynbを実行して、本章で使用するデータをダウンロード\n",
    "\n",
    "\n",
    "2. PyTorchのインストールページ（ https://pytorch.org/get-started/locally/ ）を参考に、PyTorch1.0をインストール\n",
    "\n",
    "\n",
    "conda install pytorch-cpu torchvision-cpu -c pytorch\n",
    "\n",
    "（Windowsで、GPUなしの環境をcondaでインストールする場合）\n",
    "\n",
    "\n",
    "3. Matplotlibをインストール\n",
    "\n",
    "conda install -c conda-forge matplotlib \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpQa-OCQNH2X"
   },
   "source": [
    "# パッケージのimportとPyTorchのバージョンを確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTYHPeyGNH2Y",
    "outputId": "8016dd71-2b5c-4ed6-9123-a402bdaab045",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWFzRfYwNH2Z",
    "outputId": "94fad2aa-e133-4da5-b66c-48aeebf0c40f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorchのバージョン確認\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"Torchvision Version: \", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQj18-KqNH2Z"
   },
   "source": [
    "# VGG-16の学習済みモデルをロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugoB5bhBNH2a",
    "outputId": "3756a7ab-c3d3-465d-a186-32654c18d048",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 学習済みのVGG-16モデルをロード\n",
    "# 初めて実行する際は、学習済みパラメータをダウンロードするため、実行に時間がかかります\n",
    "\n",
    "# VGG-16モデルのインスタンスを生成\n",
    "use_pretrained = True  # 学習済みのパラメータを使用\n",
    "net = models.vgg16(pretrained=use_pretrained)\n",
    "net.eval()  # 推論モードに設定\n",
    "\n",
    "# モデルのネットワーク構成を出力\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbnucsIQNH2a"
   },
   "source": [
    "# 入力画像の前処理クラスを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wegLsyJKNH2a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 入力画像の前処理のクラス\n",
    "class BaseTransform:\n",
    "    \"\"\"\n",
    "    画像のサイズをリサイズし、色を標準化する。\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    resize : int\n",
    "        リサイズ先の画像の大きさ。\n",
    "    mean : (R, G, B)\n",
    "        各色チャネルの平均値。\n",
    "    std : (R, G, B)\n",
    "        各色チャネルの標準偏差。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, resize, mean, std):\n",
    "        self.base_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(resize),  # 短い辺の長さがresizeの大きさになる\n",
    "                transforms.CenterCrop(resize),  # 画像中央をresize × resizeで切り取り\n",
    "                transforms.ToTensor(),  # Torchテンソルに変換\n",
    "                transforms.Normalize(mean, std),  # 色情報の標準化\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.base_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyPkp-v9NH2b",
    "outputId": "a46482ec-ece9-43ec-8a1a-e876c9c64a7e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 画像前処理の動作を確認\n",
    "\n",
    "# 1. 画像読み込み\n",
    "image_file_path = \"./data/goldenretriever-3724972_640.jpg\"\n",
    "img = Image.open(image_file_path)  # [高さ][幅][色RGB]\n",
    "\n",
    "# 2. 元の画像の表示\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# 3. 画像の前処理と処理済み画像の表示\n",
    "resize = 224\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "transform = BaseTransform(resize, mean, std)\n",
    "img_transformed = transform(img)  # torch.Size([3, 224, 224])\n",
    "\n",
    "# (色、高さ、幅)を (高さ、幅、色)に変換し、0-1に値を制限して表示\n",
    "img_transformed = img_transformed.numpy().transpose((1, 2, 0))\n",
    "img_transformed = np.clip(img_transformed, 0, 1)\n",
    "plt.imshow(img_transformed)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z2ZWxWnNH2b"
   },
   "source": [
    "# 出力結果からラベルを予測する後処理クラスを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6uWvtv09NH2c",
    "outputId": "ec37b593-1d1a-42a6-e3e3-eb12f85d53b4",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ILSVRCのラベル情報をロードし辞書型変数を生成します\n",
    "ILSVRC_class_index = json.load(open(\"./data/imagenet_class_index.json\", \"r\"))\n",
    "ILSVRC_class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fGbk8QpNH2c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 出力結果からラベルを予測する後処理クラス\n",
    "class ILSVRCPredictor:\n",
    "    \"\"\"\n",
    "    ILSVRCデータに対するモデルの出力からラベルを求める。\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    class_index : dictionary\n",
    "            クラスindexとラベル名を対応させた辞書型変数。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, class_index):\n",
    "        self.class_index = class_index\n",
    "\n",
    "    def predict_max(self, out):\n",
    "        \"\"\"\n",
    "        確率最大のILSVRCのラベル名を取得する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        out : torch.Size([1, 1000])\n",
    "            Netからの出力。\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predicted_label_name : str\n",
    "            最も予測確率が高いラベルの名前\n",
    "        \"\"\"\n",
    "        maxid = np.argmax(out.detach().numpy())\n",
    "        predicted_label_name = self.class_index[str(maxid)][1]\n",
    "\n",
    "        return predicted_label_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMbCCgJvNH2d"
   },
   "source": [
    "# 学習済みVGGモデルで手元の画像を予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EhD_ZQYNH2d",
    "outputId": "537c1193-eb83-4304-8392-e77e95cfaffd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ILSVRCのラベル情報をロードし辞意書型変数を生成します\n",
    "ILSVRC_class_index = json.load(open(\"./data/imagenet_class_index.json\", \"r\"))\n",
    "\n",
    "# ILSVRCPredictorのインスタンスを生成します\n",
    "predictor = ILSVRCPredictor(ILSVRC_class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 入力画像を読み込む\n",
    "image_file_path = \"./data/goldenretriever-3724972_640.jpg\"\n",
    "img = Image.open(image_file_path)  # [高さ][幅][色RGB]\n",
    "print(type(img), img.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 前処理の後、バッチサイズの次元を追加する\n",
    "transform = BaseTransform(resize, mean, std)  # 前処理クラス作成\n",
    "img_transformed = transform(img)  # torch.Size([3, 224, 224])\n",
    "inputs = img_transformed.unsqueeze_(0)  # torch.Size([1, 3, 224, 224])\n",
    "print(img_transformed.shape, inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# モデルに入力し、モデル出力をラベルに変換する\n",
    "out = net(inputs)  # torch.Size([1, 1000])\n",
    "result = predictor.predict_max(out)\n",
    "\n",
    "# 予測結果を出力する\n",
    "print(\"入力画像の予測結果：\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Cs8IdOrNH2d"
   },
   "source": [
    "以上"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1-1_load_vgg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
